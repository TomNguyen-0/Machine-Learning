{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "\n",
      "done testing\n",
      "\n",
      "current error:   0.43 \t\t test result:   [[1.]]\n",
      "current error:   0.43 \t\t test result:   [[-1.]]\n",
      "current error:   0.395 \t\t test result:   [[1.]]\n",
      "current error:   0.42 \t\t test result:   [[-1.]]\n",
      "current error:   0.395 \t\t test result:   [[1.]]\n",
      "current error:   0.4 \t\t test result:   [[1.]]\n",
      "current error:   0.395 \t\t test result:   [[1.]]\n",
      "current error:   0.41 \t\t test result:   [[1.]]\n",
      "current error:   0.39 \t\t test result:   [[1.]]\n",
      "current error:   0.39 \t\t test result:   [[1.]]\n",
      "current error:   0.37 \t\t test result:   [[1.]]\n",
      "current error:   0.375 \t\t test result:   [[-1.]]\n",
      "current error:   0.37 \t\t test result:   [[-1.]]\n",
      "current error:   0.375 \t\t test result:   [[1.]]\n",
      "current error:   0.365 \t\t test result:   [[1.]]\n",
      "current error:   0.365 \t\t test result:   [[1.]]\n",
      "current error:   0.365 \t\t test result:   [[1.]]\n",
      "current error:   0.37 \t\t test result:   [[-1.]]\n",
      "current error:   0.355 \t\t test result:   [[-1.]]\n",
      "current error:   0.365 \t\t test result:   [[1.]]\n",
      "current error:   0.36\n",
      "current error:   0.345\n",
      "current error:   0.365\n",
      "current error:   0.35\n",
      "current error:   0.36\n",
      "current error:   0.35\n",
      "current error:   0.36\n",
      "current error:   0.35\n",
      "current error:   0.355\n",
      "current error:   0.345\n",
      "current error:   0.345\n",
      "current error:   0.34\n",
      "current error:   0.345\n",
      "current error:   0.34\n",
      "current error:   0.35\n",
      "current error:   0.335\n",
      "current error:   0.35\n",
      "current error:   0.335\n",
      "current error:   0.345\n",
      "current error:   0.33\n",
      "current error:   0.33\n",
      "current error:   0.345\n",
      "current error:   0.32\n",
      "current error:   0.34\n",
      "current error:   0.34\n",
      "current error:   0.345\n",
      "current error:   0.345\n",
      "current error:   0.34\n",
      "current error:   0.34\n",
      "current error:   0.32\n",
      "current error:   0.335\n",
      "current error:   0.33\n",
      "current error:   0.335\n",
      "current error:   0.325\n",
      "current error:   0.335\n",
      "current error:   0.325\n",
      "current error:   0.32\n",
      "current error:   0.335\n",
      "current error:   0.31\n",
      "current error:   0.325\n",
      "current error:   0.31\n",
      "current error:   0.325\n",
      "current error:   0.315\n",
      "current error:   0.325\n",
      "current error:   0.315\n",
      "current error:   0.315\n",
      "current error:   0.315\n",
      "current error:   0.315\n",
      "current error:   0.31\n",
      "current error:   0.32\n",
      "current error:   0.315\n",
      "current error:   0.32\n",
      "current error:   0.315\n",
      "current error:   0.305\n",
      "current error:   0.3\n",
      "current error:   0.295\n",
      "current error:   0.3\n",
      "current error:   0.29\n",
      "current error:   0.3\n",
      "current error:   0.3\n",
      "current error:   0.305\n",
      "current error:   0.29\n",
      "current error:   0.295\n",
      "current error:   0.295\n",
      "current error:   0.295\n",
      "current error:   0.295\n",
      "current error:   0.295\n",
      "current error:   0.305\n",
      "current error:   0.3\n",
      "current error:   0.3\n",
      "current error:   0.305\n",
      "current error:   0.305\n",
      "current error:   0.305\n",
      "current error:   0.305\n",
      "current error:   0.305\n",
      "current error:   0.305\n",
      "current error:   0.305\n",
      "current error:   0.305\n",
      "current error:   0.31\n",
      "current error:   0.3\n",
      "current error:   0.31\n",
      "current error:   0.305\n",
      "current error:   0.305\n",
      "current error:   0.305\n",
      "current error:   0.31\n",
      "current error:   0.315\n",
      "current error:   0.3\n",
      "current error:   0.315\n",
      "current error:   0.295\n",
      "current error:   0.31\n",
      "current error:   0.285\n",
      "current error:   0.31\n",
      "current error:   0.3\n",
      "current error:   0.31\n",
      "current error:   0.295\n",
      "current error:   0.31\n",
      "current error:   0.295\n",
      "current error:   0.31\n",
      "current error:   0.295\n",
      "current error:   0.31\n",
      "current error:   0.29\n",
      "current error:   0.305\n",
      "current error:   0.29\n",
      "current error:   0.305\n",
      "current error:   0.29\n",
      "current error:   0.295\n",
      "current error:   0.295\n",
      "current error:   0.285\n",
      "current error:   0.285\n",
      "current error:   0.295\n",
      "current error:   0.295\n",
      "current error:   0.29\n",
      "current error:   0.295\n",
      "current error:   0.295\n",
      "current error:   0.295\n",
      "current error:   0.295\n",
      "current error:   0.295\n",
      "current error:   0.295\n",
      "current error:   0.295\n",
      "current error:   0.285\n",
      "current error:   0.29\n",
      "current error:   0.285\n",
      "current error:   0.29\n",
      "current error:   0.285\n",
      "current error:   0.29\n",
      "current error:   0.285\n",
      "current error:   0.285\n",
      "current error:   0.285\n",
      "current error:   0.29\n",
      "current error:   0.285\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This script is used to randomly generate a set of data points, and apply the adaboost method to classify these data points. \n",
    "\n",
    "\n",
    "\n",
    "from numpy import *\n",
    "#import data\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as py\n",
    "\n",
    "# Read data from Training or Testing file\n",
    "def func_readData(filename,option):\n",
    "    if option == 'train':\n",
    "        fid = open(filename,'r')\n",
    "        \n",
    "        label = []\n",
    "        data = None\n",
    "        while True:\n",
    "            fline = fid.readline()\n",
    "            if len(fline) == 0:     #EOF\n",
    "                break\n",
    "            label.append(int(fline[0:fline.find(':')]))\n",
    "            \n",
    "            dataNew = []\n",
    "            i = fline.find(':') + 1\n",
    "            dataNew = [float(fline[i:fline.find(',',i,-1)])]\n",
    "            while True:\n",
    "                i = fline.find(',',i,-1) + 1\n",
    "                if not i:\n",
    "                    break;\n",
    "                dataNew.append(float(fline[i:fline.find(',',i,-1)]))\n",
    "            if data is None:\n",
    "                data = py.mat(dataNew)\n",
    "            else:\n",
    "                data = py.vstack([data,py.mat(dataNew)])\n",
    "        fid.close()\n",
    "        return data,label\n",
    "    elif option == 'test':\n",
    "        fid = open(filename,'r')\n",
    "        data = None\n",
    "        while True:\n",
    "            fline = fid.readline()\n",
    "            if len(fline) == 0:     #EOF\n",
    "                break    \n",
    "            dataNew = []\n",
    "            i=0\n",
    "            while True:\n",
    "                dataNew.append(float(fline[i:fline.find(',',i,-1)])) \n",
    "                i = fline.find(',',i,-1) + 1\n",
    "                if not i:\n",
    "                    break\n",
    "            if data is None:\n",
    "                data = py.mat(dataNew)\n",
    "            else:\n",
    "                data = py.vstack([data,py.mat(dataNew)])\n",
    "        fid.close()\n",
    "        return data\n",
    "    else:\n",
    "        print ('Wrong input parameter!')\n",
    "\n",
    "\n",
    "# function for building weak classifiers, i.e.:  stump function\n",
    "\n",
    "def buildWeakStump(d,l,D): # (data, label, weight)\n",
    "    dataMatrix = py.mat(d)\n",
    "    labelmatrix = py.mat(l).T\n",
    "    m,n = py.shape(dataMatrix)\n",
    "    numstep = 10.0\n",
    "    bestStump = {}\n",
    "    bestClass = py.mat(py.zeros((5,1)))\n",
    "    minErr = py.inf\n",
    "    for i in range(n):\n",
    "        datamin = dataMatrix[:,i].min()\n",
    "        datamax = dataMatrix[:,i].max()\n",
    "        stepSize = (datamax - datamin) / numstep\n",
    "        for j in range(-1,int(numstep)+1):\n",
    "            for inequal in ['lt','gt']:\n",
    "                threshold = datamin + float(j) * stepSize\n",
    "                predict = stumpClassify(dataMatrix,i,threshold,inequal)\n",
    "                err = py.mat(py.ones((m,1)))\n",
    "                err[predict == labelmatrix] = 0\n",
    "                weighted_err = D.T * err;\n",
    "                if weighted_err < minErr:\n",
    "                    minErr = weighted_err\n",
    "                    bestClass = predict.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['threshold'] = threshold\n",
    "                    bestStump['ineq'] = inequal\n",
    "    #print('bestStump',bestStump)\n",
    "    #print('minErr',minErr)\n",
    "    #print('bestClass',bestClass)\n",
    "    return bestStump, minErr, bestClass\n",
    "\n",
    "# Use a weak classifier, i.e. a decision stump, to classify data\n",
    "\n",
    "def stumpClassify(datamat,dim,threshold,inequal):\n",
    "    res = py.ones((py.shape(datamat)[0],1))\n",
    "    if inequal == 'lt':\n",
    "        res[datamat[:,dim] <= threshold] = -1.0\n",
    "    else:\n",
    "        res[datamat[:,dim] > threshold] = -1.0\n",
    "    return res\n",
    "\n",
    "# Boosting Algorithm\n",
    "\n",
    "def train(data,label,numIt = 1000):\n",
    "    report_train=[]\n",
    "    weakClassifiers = []\n",
    "    #m is the number of samples\n",
    "    m = py.shape(data)[0]\n",
    "    # sample weights, 1/m at the beginning\n",
    "    D = py.mat(py.ones((m,1))/m) \n",
    "    \n",
    "    estStrong = py.mat(py.zeros((m,1)))\n",
    "    for i in range(numIt):\n",
    "        # bestStump: weak classifier; error: error rate\n",
    "        bestStump, error, classEstimate = buildWeakStump(data,label,D)\n",
    "        \n",
    "        \n",
    "        ##### PLACEHOLDER 1 START ###\n",
    "    # calculate the weight of the selected decision stump based on its error rate\n",
    "        current_iteration = 1e-16 #small constant\n",
    "        top = 1.0 - error\n",
    "        bottom = error + current_iteration\n",
    "        alpha =  float(0.5*log(top / bottom))##slide 29 from lecture 9\n",
    "        ##### PLACEHOLDER 1 End ###\n",
    "        \n",
    "        # add one more field to bestStump, i.e. classifier weight\n",
    "        bestStump['alpha'] = alpha\n",
    "        # add bestStump to the list of weak classifiers\n",
    "        weakClassifiers.append(bestStump)\n",
    "\n",
    "        ##### PLACEHOLDER 2 START ###\n",
    "        #calculate sample weights (of all samples) \n",
    "    # set sample weights\n",
    "        negative_alpha = -1 * alpha\n",
    "        y_i = mat(label)\n",
    "        h_t = (negative_alpha*y_i).T#transpose\n",
    "        weight_sample=py.multiply(h_t,classEstimate)##slide 31\n",
    "        D= py.multiply(D,exp(weight_sample))##slide 31\n",
    "        # normalize D\n",
    "        D = D/D.sum()\n",
    "        ##### PLACEHOLDER 2 End ###\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        estStrong += classEstimate*alpha\n",
    "        \n",
    "        EnsembleErrors = py.multiply(py.sign(estStrong)!=py.mat(label).T,\\\n",
    "                                  py.ones((m,1)))  #Converte to float\n",
    "        \n",
    "        errorRate = EnsembleErrors.sum()/m\n",
    "        \n",
    "        #print (\"current error:  \",errorRate)\n",
    "        report_train.append(errorRate)\n",
    "        if errorRate == 0.0:\n",
    "            break\n",
    "    return report_train, weakClassifiers\n",
    "\n",
    "# Applying an adaboost classifier for a single data sample\n",
    "\n",
    "def adaboostClassify(dataTest,classifier):\n",
    "    dataMatrix = py.mat(dataTest)\n",
    "    m = py.shape(dataMatrix)[0]\n",
    "    estStrong = py.mat(py.zeros((m,1)))\n",
    "    for i in range(len(classifier)):\n",
    "        ##### PLACEHOLDER 3 START ###\n",
    "        # call the function stumpClassify()\n",
    "        class_threshold = classifier[i]['threshold']\n",
    "        class_dim = classifier[i]['dim']\n",
    "        class_ineq =classifier[i]['ineq']\n",
    "        classEstimate = stumpClassify(dataMatrix,class_dim,class_threshold,class_ineq)\n",
    "        # accumulate all predictions\n",
    "        estStrong += classifier[i]['alpha']*classEstimate\n",
    "        ##### PLACEHOLDER 3 START ###       \n",
    "    return py.sign(estStrong)\n",
    "\n",
    "# Applying an adaboost classifier for all testing samples\n",
    "def test(dataSet,classifier):\n",
    "    label = []\n",
    "    for i in range(py.shape(dataSet)[0]):\n",
    "        label.append(adaboostClassify(dataSet[i,:],classifier))\n",
    "    return label\n",
    "\n",
    "\n",
    "#############. main ##################\n",
    "# The data files \"train.txt\" and \"test.txt\" are randomly generated by the function randomData() and are used to test your developed codes.\n",
    "\n",
    "trainData,label = func_readData('train.txt','train')\n",
    "testData = func_readData('test.txt','test')\n",
    "'''copy_train = deepcopy(trainData)\n",
    "copy_label = deepcopy(label)\n",
    "new=[]\n",
    "for i in range(len(trainData)):\n",
    "    new.append([trainData[i],label[i]])\n",
    "random.shuffle(new)\n",
    "for i in range(len(trainData)):\n",
    "    copy_train[i]=new[i][0]\n",
    "    copy_label[i]=new[i][1]'''\n",
    "#print(trainData)\n",
    "'''trainData=copy_train\n",
    "label=copy_label'''\n",
    "#print(trainData)\n",
    "\n",
    "#training\n",
    "report,classifier = train(trainData,label,150)\n",
    "print('done training\\n')\n",
    "#testing\n",
    "label=test(testData,classifier)\n",
    "print('done testing\\n')\n",
    "for i in range(len(report)):\n",
    "    if i < len(label):\n",
    "        print (\"current error:  \",report[i],\"\\t\\t test result:  \",label[i])\n",
    "    else:\n",
    "        print (\"current error:  \",report[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
