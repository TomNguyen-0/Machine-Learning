# -*- coding: utf-8 -*-
"""main_ha5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hEeuH8L4X9sMV_VyYBNIeAt1HV8ZGaej
"""

#ten videos for machine learning: https://www.youtube.com/watch?v=cSKfRcEDGUs&list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal&index=6
#mnist handwritten digit recognition in keras: https://nextjournal.com/a/17592186058848
#use as a guide : https://elitedatascience.com/keras-tutorial-deep-learning-in-python#step-2

import numpy as np
import scipy
import matplotlib.pyplot as plt
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.utils import np_utils

import numpy as np
from sklearn import metrics

#function [CM, acc, arrR, arrP]=func_confusion_matrix(teY, hatY)

def func_confusion_matrix(y_test, y_pred):
    """ this function is used to calculate the confusion matrix and a set of metrics.
    INPUT:
        y_test, ground-truth lables;
        y_pred, predicted labels;
    OUTPUT:
        CM, confuction matrix
        acc, accuracy
        arrR[], per-class recall rate,
        arrP[], per-class prediction rate.
    """

    y_test = np.array(y_test)
    y_pred = np.array(y_pred)

    unique_values = set(y_pred)
    sorted(unique_values)
    num_classes = len(unique_values)
    unique_values = np.array(list(unique_values)) # change to array so can use indexes
    possible_string_dict = {}
    # make sure all values are 0 based, so can use built-in "zip" function
    if(issubclass(type(y_test[0]), np.integer)): # if values are integers
        y_test_min = y_test.min()
        if(y_test_min != 0):# if does not contain 0, reduce both test and pred by min value to get 0 based for both
            y_test = y_test - y_test_min;
            y_pred = y_pred - y_test_min;
    else:
        # assume values are strings, change to integers
        # TODO, change to convert list from string to int
        y_test_int = np.empty(len(y_test), dtype=int)
        y_pred_int = np.empty(len(y_pred), dtype=int)
        for index in range(0, num_classes):
            current_value = unique_values[index]
            possible_string_dict[index] = current_value
            y_test_int[y_test == current_value] = index
            y_pred_int[y_pred == current_value] = index
        y_test = y_test_int
        y_pred = y_pred_int
       
    ## your code for creating confusion matrix;
    conf_matrix = np.zeros((num_classes, num_classes), dtype=np.int)
    for a, p in zip(y_test, y_pred):
        conf_matrix[a][p] += 1
 

    ## your code for calcuating acc;
    accuracy = conf_matrix.diagonal().sum() / conf_matrix.sum()
   
    ## your code for calcualting arrR and arrP;
    recall_array = np.empty(num_classes, dtype=float)
    precision_array = np.empty(num_classes, dtype=float)
    for index in range(0, num_classes):
        value = conf_matrix[index,index]
        recall_sum = conf_matrix[index,:].sum()
        precision_sum = conf_matrix[:, index].sum()
        recall_array[index] = value / recall_sum
        precision_array[index] = value / precision_sum
       
    return conf_matrix, accuracy, recall_array, precision_array


def get_confusion_matrix_and_test(y_test, y_pred):
    """ get confusion matrix, accuracy, array of recall and precision
        test confusion matrix and accuracy
    """
    cm, acc, arrR, arrP = func_confusion_matrix(y_test, y_pred)
    expected_matrix = metrics.confusion_matrix(y_test, y_pred)
    assert(np.array_equal(expected_matrix, cm))
    expected_acc = metrics.accuracy_score(y_test, y_pred)
    assert(round(expected_acc, 2) == round(acc, 2))
    return cm, acc, arrR, arrP

def _test_confusion_matrix():
    y_test = [1, 1, 1, 1, 1,
              2, 2, 2, 2, 2, 2, 2, 2,
              3, 3, 3, 3, 3, 3, 3]
    y_pred = [2, 1, 2, 2, 3,
              2, 2, 1, 1, 3, 3, 2, 1,
              1, 1, 3, 3, 2, 2, 3]
    cm, acc, arrR, arrP = get_confusion_matrix_and_test(y_test, y_pred)

def _perform1point1(confidence_threshold):
    y_test = ['Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'N', 'N', 'N', 'N', 'N']
    y_pred_conf = [0.95, 0.83, 0.78, 0.53, 0.9, 0.2, 0.6, 0.8, 0.7, 0.5, 0.9, 0.2]
    num_elements = len(y_pred_conf)
    y_pred = np.empty(num_elements, dtype=object)
    for index in range(0, num_elements):
        if y_pred_conf[index] > confidence_threshold:
            y_pred[index] = 'Y'
        else:
            y_pred[index] = 'N'

    cm, acc, arrR, arrP = get_confusion_matrix_and_test(y_test, y_pred)
   

### Main function.  Not called if imported elsewhere as a module.
'''
if __name__ == "__main__":
    # test with example from previous Machine Learning class homework
    # _test_confusion_matrix()
    _perform1point1(0.6)
'''

# load (downloaded if needed) the MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

########plt.imshow(y_train[0])
#print(x_train.shape)#(60000, 28, 28)
#print(y_train.shape)#(60000,)
#print(x_test.shape)#(10000, 28, 28)
#print(y_test.shape)#(10000,)
#plt.imshow(x_train[0])#prints out a 5
#print(len(x_test))#10000
#print(len(x_train))#60000
#Y_train = np_utils.to_categorical(y_train,10)

#Y_test = np_utils.to_categorical(y_test,10)

# transform each image from 28 by28 to a 784 pixel vector
pixel_count = x_train.shape[1] * x_train.shape[2] #784

#print(x_train.shape)#(60000, 28, 28)
x_train = x_train.reshape(x_train.shape[0], pixel_count).astype('float32')#[[0. 0. 0. ... 0. 0. 0.]
#print(x_train.shape)#(60000, 784)
x_test = x_test.reshape(x_test.shape[0], pixel_count).astype('float32')

# normalize inputs from gray scale of 0-255 to values between 0-1
x_train = x_train / 255 #60,000
x_test = x_test / 255

X_train= x_train[:50000] #training set size 50000
#print(X_train[0])#[0.         0.         0.         0.         0.         0.
X_validation = x_train[50000:] #validation set size 10000
#Y_train= y_train[:50000]
#Y_train= y_train[50000:]#print(,Y_train.shape)#(10000,)
Y_train = np_utils.to_categorical(y_train[:50000],10)

Y_test = np_utils.to_categorical(y_train[50000:],10)
#print number index 0 and its prediction
#print(x_train[2].shape) # need to resahpe it to 28 by 28? (784,)
#plt.imshow(x_train[2])#invalid dimensions
#print(y_train[2])#4

def hyper_parameter(neurons, neurons2, dropout,X_train,Y_train,x_test,y_test,pixel_count,yy_test):
  model = Sequential() # the type of model
  model.add(Dense(neurons, input_shape=(pixel_count,))) #the input layer #pixel_count=784
  model.add(Activation('relu')) # the activation function of layer 1
  model.add(Dropout(dropout)) #percent of neurons we turn off randomly in layer 1
  model.add(Dense(neurons2)) #the hidden layer
  model.add(Activation('relu')) # the activation function of layer 2
  model.add(Dropout(dropout)) #percent of neurons we turn off randomly in layer 2
  model.add(Dense(10)) #the output layer with 10 output classes
  model.add(Activation('softmax')) #We want a score simlar to a probability for each class
  model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')
  history=model.fit(X_train, Y_train, batch_size=128, epochs=8, verbose=2,
                    validation_data=(x_test, y_test))
  fig = plt.figure()
  plt.subplot(2,1,1)
  plt.plot(history.history['acc'])
  plt.plot(history.history['val_acc'])
  plt.title('model accuracy')
  plt.ylabel('accuracy')
  plt.xlabel('epoch')
  plt.legend(['train', 'test'], loc='lower right')

  plt.subplot(2,1,2)
  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  plt.title('model loss')
  plt.ylabel('loss')
  plt.xlabel('epoch')
  plt.legend(['train', 'test'], loc='upper right')
  plt.tight_layout()
  fig
  
  scores = model.evaluate(X_validation, Y_test, verbose=0)
  predicted_classes = model.predict_classes(x_test)#print(predicted_classes)#[7 2 1 ... 4 5 6]
  correct_indices = np.nonzero(predicted_classes == yy_test)[0]# print(yy_test.shape)#(10000,)
  incorrect_indices = np.nonzero(predicted_classes != yy_test)[0]
  print()
  print(len(correct_indices)," classified correctly")
  print(len(incorrect_indices)," classified incorrectly")
  plt.rcParams['figure.figsize'] = (7,14)# adapt figure size to accomodate 18 subplots
  figure_evaluation = plt.figure()
  for i, correct in enumerate(correct_indices[:9]):
    plt.subplot(6,3,i+1)
    plt.imshow(x_test[correct].reshape(28,28), cmap='gray', interpolation='none')
    plt.title("Predicted {}, Class {}".format(predicted_classes[correct], yy_test[correct]))
    plt.xticks([])
    plt.yticks([])
  for i, incorrect in enumerate(incorrect_indices[:9]):
    plt.subplot(6,3,i+10)
    plt.imshow(x_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')
    plt.title("Predicted {}, Class {}".format(predicted_classes[incorrect], yy_test[incorrect]))
    plt.xticks([])
    plt.yticks([])
  figure_evaluation
  confusion=func_confusion_matrix(yy_test,predicted_classes)
  return scores,confusion
  
#print(y_train[:10])#[5 0 4 1 9 2 1 3 1 4]
#plt.imshow(x_train[:0])

#Define the model achitecture, This is where the hyperparameters are defined
#hyper paramters = neurons,dropout rates, activation functions 
layer1_neurons=[256,512,784,1024,1568,2048]
layer2_neurons=[256,512,784,1024,1568,2048]
dropout=[0.1,0.05,0.2,0.1,0.05,0.2]


#print(Y_test.shape)#[[0. 0. 0. ... 1. 0. 0.]#(10000, 10)
yy_test=y_test
y_test = np_utils.to_categorical(y_test,10)
#Make the model learn

#print(x_test.shape)#(10000, 784)
#print(y_test.shape)#(10000,)
#print(Y_test.shape)#(10000, 10)
#Evaluate how the model does on the test set

#each element is a list containing all of the results of
#training the netwaork with one set of hyperparameters
scores=[]
confus=[]

for i in range(len(layer1_neurons)):
  part1,part2=hyper_parameter(layer1_neurons[i],layer2_neurons[i],dropout[i],X_train,Y_train,x_test,y_test,pixel_count,yy_test)
  scores.append(part1)
  confus.append(part2)

for j in range(len(scores)):
  confus[j]
  print('Test score: ',scores[j][0])
  print('Test accuracy: ',scores[j][1])